{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Breast Cancer\n",
    "\n",
    "Predict whether a tumor is malignant or benign.\n",
    "\n",
    "##About Dataset\n",
    "\n",
    "###Description:\n",
    "\n",
    "Breast cancer is the most prevalent cancer among women globally, accounting for 25% of all cancer cases. In 2015 alone, it impacted over 2.1 million individuals. The disease begins when cells in the breast grow uncontrollably, forming tumors that can be detected via X-ray or felt as lumps.\n",
    "\n",
    "\n",
    "The primary challenge in its detection is classifying tumors as malignant (cancerous) or benign (non-cancerous). We invite you to analyze and classify these tumors using machine learning techniques, specifically Support Vector Machines (SVMs), with the Breast Cancer Wisconsin (Diagnostic) Dataset.\n",
    "\n",
    "\n",
    "###Acknowledgements:\n",
    "\n",
    "This dataset is sourced from Kaggle.\n",
    "\n",
    "###Objective:\n",
    "\n",
    "Understand and clean the dataset if necessary.\n",
    "Build classification models to predict if the cancer is malignant or benign.\n",
    "Fine-tune hyperparameters and compare the performance of various classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabri\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/rahmasleam/breast-cancer?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48.6k/48.6k [00:00<00:00, 12.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: C:\\Users\\fabri\\.cache\\kagglehub\\datasets\\rahmasleam\\breast-cancer\\versions\\1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rahmasleam/breast-cancer\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamento e limpeza dos dados\n",
    "\n",
    "Lemos o arquivo CSV com pandas (pd.read_csv(...)).\n",
    "Exploramos o DataFrame usando métodos como df.head() e df.info().\n",
    "Removemos a coluna id, pois geralmente não possui valor preditivo para o diagnóstico.\n",
    "Checamos se há valores nulos e, caso existam, decidimos como tratá-los (ex.: apagar linhas, preencher com média etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\fabri\\.cache\\kagglehub\\datasets\\rahmasleam\\breast-cancer\\versions\\1\\breast-cancer.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diagnosis                  0\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformar a coluna de diagnóstico\n",
    "\n",
    "Convertemos a coluna diagnosis para valores numéricos, onde “M” = 1 (maligno) e “B” = 0 (benigno). Isso facilita o uso de modelos de classificação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "B    357\n",
       "M    212\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis']=df['diagnosis'].map({'B': 0, 'M' : 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar o conjunto de dados em X (features) e y (target)\n",
    "\n",
    "X contém todas as colunas de características (ex.: radius_mean, perimeter_mean, etc.).\n",
    "y contém apenas a coluna-alvo (diagnosis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('diagnosis', axis=1)\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividir em treino e teste\n",
    "\n",
    "Utilizamos train_test_split para dividir os dados em um conjunto de treino (para ajustar o modelo) e um conjunto de teste (para avaliar o modelo em dados “desconhecidos”).\n",
    "test_size=0.3 significa que 30% dos dados serão usados para teste.\n",
    "random_state=42 apenas garante reprodutibilidade (opcional).\n",
    "stratify=y garante que a proporção de classes (M vs B) se mantém equilibrada nos dois conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escalonar (padronizar) os dados\n",
    "\n",
    "Alguns algoritmos (especialmente aqueles baseados em distância ou que fazem otimização por gradiente, como a Regressão Logística) têm desempenho melhor quando as variáveis estão na mesma escala.\n",
    "O StandardScaler transforma cada feature para que tenha média 0 e desvio padrão 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinar um modelo de classificação\n",
    "\n",
    "Regressão Logística: É frequentemente um dos primeiros modelos testados, fácil de interpretar e muitas vezes apresenta bons resultados para esse tipo de problema.\n",
    "Random Forest: Algoritmo de ensemble que costuma ter boa performance em problemas com muitas features.\n",
    "\n",
    "Avaliar o modelo\n",
    "\n",
    "A acurácia (accuracy_score) mede a porcentagem de classificações corretas.\n",
    "A matriz de confusão (confusion_matrix) mostra quantos acertos e erros existem para cada classe.\n",
    "O relatório de classificação (classification_report) exibe métricas de precisão (precision), revocação (recall) e pontuação F1, úteis para avaliar o desempenho principalmente em casos de classe desbalanceada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Regressão Logística ===\n",
      "Acurácia no teste:  0.9707602339181286\n",
      "Matriz de confusão:\n",
      " [[106   1]\n",
      " [  4  60]]\n",
      "Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       107\n",
      "           1       0.98      0.94      0.96        64\n",
      "\n",
      "    accuracy                           0.97       171\n",
      "   macro avg       0.97      0.96      0.97       171\n",
      "weighted avg       0.97      0.97      0.97       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7) Treinar um modelo de classificação\n",
    "#    Exemplo 1: Regressão Logística\n",
    "\n",
    "logreg = LogisticRegression(max_iter=10000)\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_logreg = logreg.predict(X_test_scaled)\n",
    "\n",
    "# Avaliação do modelo de Regressão Logística\n",
    "print('\\n=== Regressão Logística ===')\n",
    "print('Acurácia no teste: ', accuracy_score(y_test, y_pred_logreg))\n",
    "print('Matriz de confusão:\\n', confusion_matrix(y_test, y_pred_logreg))\n",
    "print('Relatório de classificação:\\n', classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest ===\n",
      "Acurácia no teste:  0.9649122807017544\n",
      "Matriz de confusão:\n",
      " [[107   0]\n",
      " [  6  58]]\n",
      "Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       107\n",
      "           1       1.00      0.91      0.95        64\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.95      0.96       171\n",
      "weighted avg       0.97      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#    Exemplo 2: Random Forest\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "# Avaliação do modelo de Random Forest\n",
    "print('\\n=== Random Forest ===')\n",
    "print('Acurácia no teste: ', accuracy_score(y_test, y_pred_rf))\n",
    "print('Matriz de confusão:\\n', confusion_matrix(y_test, y_pred_rf))\n",
    "print('Relatório de classificação:\\n', classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previsão de apenas 1 amostra do próprio conjunto de teste\n",
    "Suponha que você queira prever o diagnóstico para a primeira amostra do conjunto de teste (X_test) e comparar com o valor real (y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição (0 = Benigno, 1 = Maligno):  0\n",
      "Valor real:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabri\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1) Pegamos uma única amostra do X_test\n",
    "amostra_unica = X_test.iloc[0]  # Series com as features\n",
    "\n",
    "# 2) É preciso escalonar essa amostra, pois o modelo foi treinado em dados escalonados\n",
    "amostra_unica_escalonada = scaler.transform([amostra_unica])  # transforma em array 2D\n",
    "\n",
    "# 3) Fazer a predição\n",
    "predicao = logreg.predict(amostra_unica_escalonada)\n",
    "\n",
    "print(\"Predição (0 = Benigno, 1 = Maligno): \", predicao[0])\n",
    "\n",
    "# 4) Comparar com o valor real em y_test\n",
    "print(\"Valor real: \", y_test.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previsão de um caso novo (fora do dataset)\n",
    "Imagine que você tenha os valores de uma paciente que não está no dataset e queira fazer a predição. Suponha que sejam 30 colunas (excluindo o diagnosis), e que estejam na mesma ordem e nome das colunas que você usou para treinar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição (0 = Benigno, 1 = Maligno): 1\n",
      "Probabilidades [Classe 0, Classe 1]: [0.00555341 0.99444659]\n"
     ]
    }
   ],
   "source": [
    "# Exemplo FICTÍCIO de valores de entrada, apenas ilustrativo\n",
    "# Certifique-se de que a ordem das colunas corresponde à usada no treino.\n",
    "# Por exemplo: [radius_mean, texture_mean, perimeter_mean, ..., fractal_dimension_worst]\n",
    "valores_novos = [\n",
    "    15.50,  20.20,  120.9,  800.0,  0.100,  0.200,  0.150,  0.050, \n",
    "    0.160,  0.055,  0.800,  0.900,  5.000,  85.50,  0.007,  0.040,\n",
    "    0.045,  0.010,  0.035,  0.008,  22.0,   25.0,   150.0,  1200.0,\n",
    "    0.150,  0.250,  0.300,  0.150,  0.300,  0.080\n",
    "]\n",
    "\n",
    "# Vamos criar um DataFrame com 1 linha, usando exatamente as colunas de X\n",
    "df_novo = pd.DataFrame([valores_novos], columns=x.columns)\n",
    "\n",
    "# Escalonar\n",
    "df_novo_scaled = scaler.transform(df_novo)\n",
    "\n",
    "# Fazer a predição\n",
    "pred_novo = logreg.predict(df_novo_scaled)\n",
    "\n",
    "# Ver probabilidade de cada classe\n",
    "prob_novo = logreg.predict_proba(df_novo_scaled)\n",
    "\n",
    "print(\"Predição (0 = Benigno, 1 = Maligno):\", pred_novo[0])\n",
    "print(\"Probabilidades [Classe 0, Classe 1]:\", prob_novo[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
